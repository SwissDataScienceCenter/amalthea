# Default values for the jupyter-server-operator chart
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Indicate the scope which this operator watches for
# JupyterServer resources.
scope:
  # It is recommended to limit the scope of Amalthea to some
  # explicitly mentioned namespaces for two reasons:
  # 1. Amalthea needs pretty extensive permissions on the namespace
  #    in which it operates.
  # 2. Cluster-wide network policies do not yet exist in Kubernetes.
  #    Therefore, no network policies are automatically added for
  #    cluster-wide deployments and admins will need to set up appropriate
  #    network policies manually.
  clusterWide: false
  # Namespaces should not be provided if clusterWide is true.
  # If the deployment is not clusterwide, then there are two options:
  # 1. Specify the namespaces where amalthea should operate
  # 2. Do not define namespaces at all, in which case amalthea
  #    will only operate in the namespace where the helm chart is deployed.
  # namespaces: ["default"]

deployCrd: true # whether to deploy the jupyterserver CRD

networkPolicies:
  # # Enable sensible, default network policies. Note that until cluster-wide 
  # # network policies are available in Kubernetes (https://github.com/kubernetes/enhancements/issues/2091),
  # # enabling network policies for the servers won't do anything if the scope of the
  # # operator is set to clusterWide. These default policies disable all ingress
  # # to the controller pod and also apply the following policies to all
  # # jupyter server pods:
  # #   - egress: allowed only for DNS resolution inside and outside the cluster
  # #             and for going to any address/port/etc as long as it is outside of the cluster,
  # #             i.e. egresses from jupyter servers aimed at other things within the k8s cluster
  # #             are blocked
  # #   - ingress: allowed only on port 4180 for TCP so that the oauth2proxy can be reached
  enabled: true

kopf:
  # # Configure the kopf operator settings by providing
  # # a yaml object as multiline string. See
  # # https://kopf.readthedocs.io/en/stable/configuration/
  # # for configuraiton options.
  startupConfiguration: |
    watching:
      # This can fix a problem of a watch stream suddenly falling
      # silent, see https://github.com/nolar/kopf/issues/762#issuecomment-838423267
      client_timeout: 600
  # # Configure the use of timeout, delay and backoff for the successful creation
  # # of k8s resources by the operator. Leaving out timeout or retries results
  # # in the operator permanently retrying and never giving up when it encounters
  # # erors during the k8s resource creation phase.
  # onCreate:
  #   timeout: 600
  #   retries: 60
  #   backoff: 10

# If the operator should be able to create and watch child resources other than
# [statefulset, persistentvolumeclaims, services, ingresses, secrets, configmaps]
# which are necessary for Amalthea to work, add the corresponding API groups and
# resources here as an array of name/group objects, eg:
extraChildResources: []
  # - name: jupyterservers
  #   group: amalthea.dev

image:
  repository: renku/amalthea
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext: {}

securityContext: {}

resources:
  limits:
    cpu: 100m
    memory: 128Mi
  requests:
    cpu: 100m
    memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}

# Specify API group, version and custom resource names. You will very
# likely never want to change any of this! This is mostly useful for
# dev purposes as it allows multiple otherwise incompatible versions of
# the CRD to co-exist in one cluster.
crdApiGroup: amalthea.dev
crdApiVersion: v1alpha1
crdNames:
  kind: JupyterServer
  plural: jupyterservers
  singular: jupyterserver
  shortNames:
    - js

# Determine how often amalthea checks each server to determine whether it is idle.
# The criteria for deeming that a server is idle are based on the cpu usage
# and the stats provided by the jupyter server /api/status endpoint. The culling
# section of the custom resource definition of JupyterServer can be used to control
# on a per-server basis whether a server is ever culled and also if it is culled then
# how long each server is idle for before it is culled.
culling:
  jupyterServerIdleCheckIntervalSeconds: 300
  cpuUsageMillicoresIdleThreshold: 500

# Deploy an optional additional scheduler in the same namespace where the operator is deployed.
# The additional scheduler allows for fine grained scheduling policies for the pods managed by this operator.
# As an example the pods can be scheduled to prioritize the most requested nodes, thus "packing" the workload in
# as few nodes as possible, instead of spreading them over all the available nodes.
# NOTE: ensure that the tag of the scheduler image matches the version of the Kubernetes cluster where it is deployed.
scheduler:
  enable: false
  image:
    repository: k8s.gcr.io/kube-scheduler
    pullPolicy: IfNotPresent
    tag: you-MUST-set-a-tag-matching-the-k8s-version-in-your-cluster
  priorities:
    - name: MostRequestedPriority
      weight: 100
    - name: ServiceSpreadingPriority
      weight: 1
    - name: EqualPriority
      weight: 1
    - name: ImageLocalityPriority
      weight: 1
    - name: SelectorSpreadPriority
      weight: 1
    - name: InterPodAffinityPriority
      weight: 1
    - name: LeastRequestedPriority
      weight: 1
    - name: BalancedResourceAllocation
      weight: 1
    - name: NodePreferAvoidPodsPriority
      weight: 1
    - name: NodeAffinityPriority
      weight: 1
    - name: TaintTolerationPriority
      weight: 1
